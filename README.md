# Text-Based-News-Summarization
Used extractive and abstractive methods to generate news article summaries, and compared them to those generated by humans using a metric known as the ROUGE-L (RecallOriented Understudy for Gisting Evaluation) score

### Description

Do you open news websites and immediately begin reading every news article? Most likely
not. People usually skim the short news articles and keep scrolling through and reading
more details if the article’s summary has piqued the reader's interest. Short, informative
summaries of the news turn out to be very useful in such cases. Text Summarization refers
to the process of extracting these summaries from the original news article preserving the
vital information and relevant context. We aim to develop a solution to this problem by
building a model using Natural Language Processing techniques for select categories of
news articles i.e sports, politics, business, and entertainment. Initially, we use a clustering
algorithm to find the category of our news article and then employ a specific text
summarization algorithm to summarize that category of the news article. In a nutshell, we
aim to develop multimodal machine learning algorithms to cluster news articles and then
summarize them.

### Data

The data set consists of following attributes:
- id: a string containing the heximal formatted SHA1 hash of the url where the story
was retrieved from
- article: a string containing the body of the news article
- highlights: a string containing the highlight of the article as written by the article
author
The CNN/DailyMail dataset has 3 splits: train, validation, and test. The train set consists of
287,113 instances while the validation and test sets contain 13,368 and 11,490 instances
respectively.
(Sources:https://www.kaggle.com/gowrishankarp/newspaper-text-summarization-cnn-dailymail)

### Evaluation Metrics
ROUGE Score - ROUGE-L
ROUGE-L measures Longest Common Subsequence(LCS) between our TextRank output and
highlights. Longer shared subsequence would indicate more similarity between two
sequences

### Summarize Approach and Future Directions
In this study, we developed an extractive summarizer using
the Text Rank algorithm to extract summaries from the
original articles. In order to replicate human generated
highlights, we implemented a bidirectional encoder-decoder
architecture with two recurrent layers, one for learning past
textual context and the other for learning future textual
context. The encoder’s output was fed into the decoder. Then,
one by one, tokens for the final summary are generated using
a unidirectional LSTM. Finally, we use the ROUGE-L score
to compare the predicted summaries with the expert
generated summaries.
The next step to improve the predicted summaries is
to augment the Seq2Seq model with attention with a Pointer
Generator neural network that allows both copying words via
pointing and generating words from a fixed vocabulary.
Furthermore, coverage mechanism can be implemented to
keep track of what has been summarized.
